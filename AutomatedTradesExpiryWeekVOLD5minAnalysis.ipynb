{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every possible analysis on VOLD crossovers for the 5 min chart timeframe\n",
    "\n",
    "1. VOLD crossover from below 0 to above 0\n",
    "2. VOLD crossover from below 0 to above 0 before 9:30 AM\n",
    "3. VOLD crossover from below 0 to above 0 and carry over the trade to max profit or until VOLD crosses down below 0 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NSE_NIFTY240627C23500, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627C23500, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627C23600, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627C23600, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627C23700, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627C23700, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627C23750, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627C23750, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627C23800, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627C23800, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627P23600, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627P23600, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627P23700, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627P23700, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240627P23800, 5.csv in NIFTY...\n",
      "Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240627P23800, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C23800, 5.csv in NIFTY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n",
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240704C23800, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C23900, 5.csv in NIFTY...\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240704C23900, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C24000, 5.csv in NIFTY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n",
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240704C24000, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C24050, 5.csv in NIFTY...\n",
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240704C24050, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C24100, 5.csv in NIFTY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n",
      "C:\\temp\\ipykernel_16264\\1091108595.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No buy signals found before 9:30 AM IST for NSE_NIFTY240704C24100, 5.csv. Skipping...\n",
      "Processing NSE_NIFTY240704C24150, 5.csv in NIFTY...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to filter buy signals based on VOLD crossover\n",
    "def filter_signals_vold_crossover(data, time_limit=None):\n",
    "    if 'Normalized VOLD Ratio' not in data.columns:\n",
    "        print(\"Warning: 'Normalized VOLD Ratio' column not found in the data. Skipping this file.\")\n",
    "        return None\n",
    "\n",
    "    buy_signals = data[(data['Normalized VOLD Ratio'].shift(1) < 0) & (data['Normalized VOLD Ratio'] > 0)]\n",
    "    \n",
    "    if time_limit:\n",
    "        buy_signals['time_ist'] = pd.to_datetime(buy_signals['time'], unit='s') + timedelta(hours=5, minutes=30)\n",
    "        buy_signals = buy_signals[buy_signals['time_ist'].dt.time <= time_limit]\n",
    "\n",
    "    return buy_signals\n",
    "\n",
    "# Function to calculate charges\n",
    "def calculate_charges(entry_price, exit_price, quantity):\n",
    "    brokerage = 40  # total brokerage for one complete buy and sell\n",
    "    stt_ctt = 0.00125 * exit_price * quantity\n",
    "    transaction_charges = 0.000495 * (entry_price + exit_price) * quantity\n",
    "    gst = 0.18 * (brokerage + transaction_charges)\n",
    "    sebi_charges = 10 / 10**7 * (entry_price + exit_price) * quantity\n",
    "    stamp_charges = 0.00003 * entry_price * quantity\n",
    "    total_charges = brokerage + stt_ctt + transaction_charges + gst + sebi_charges + stamp_charges\n",
    "    return total_charges\n",
    "\n",
    "# Function to simulate day trades with error margin\n",
    "def simulate_day_trades(buy_signals, minute_data, symbol, profit_target=0.02, stop_loss=0.01, min_stop_loss=0.005, error_margin=0.01, carry_over=False):\n",
    "    results = []\n",
    "\n",
    "    for index, buy_signal in buy_signals.iterrows():\n",
    "        entry_price = buy_signal['close'] * (1 + error_margin)  # Adjust entry price with error margin\n",
    "        entry_time = buy_signal['time'] + 300  # Add 5 minutes to the buy signal time to get the entry time\n",
    "        \n",
    "        # Convert entry_time from epoch to datetime\n",
    "        entry_datetime = pd.to_datetime(entry_time, unit='s')\n",
    "        entry_datetime_ist = entry_datetime + timedelta(hours=5, minutes=30)  # Convert to IST\n",
    "        \n",
    "        profit_price = entry_price * (1 + float(profit_target))\n",
    "        stop_price = entry_price * (1 - max(float(stop_loss), min_stop_loss))  # Ensure stop loss is at least min_stop_loss\n",
    "        \n",
    "        trade_result = {\n",
    "            'signal_time': buy_signal['time'],\n",
    "            'entry_time': entry_time,\n",
    "            'entry_price': entry_price,\n",
    "            'Target Profit': profit_target,\n",
    "            'Stop Loss': stop_loss,\n",
    "            'Profit Price': profit_price,\n",
    "            'Stop Price': stop_price,\n",
    "            'exit_time': None,\n",
    "            'exit_price': None,\n",
    "            'charges': None,\n",
    "            'profit_before_charges': None,\n",
    "            'profit': None,\n",
    "            'exit_reason': None,\n",
    "            'SOSI': buy_signal.get('SOSI'),\n",
    "            'Normalized VOLD Ratio': buy_signal.get('Normalized VOLD Ratio'),\n",
    "            'Normalized Theta': buy_signal.get('Normalized Theta')\n",
    "        }\n",
    "        \n",
    "        # Filter subsequent data for the same day only\n",
    "        trade_date = pd.to_datetime(entry_time, unit='s').date()\n",
    "        subsequent_data = minute_data[(minute_data['time'] > entry_time) & \n",
    "                                      (pd.to_datetime(minute_data['time'], unit='s').dt.date == trade_date)]\n",
    "        \n",
    "        for _, row in subsequent_data.iterrows():\n",
    "            if row['high'] >= profit_price:\n",
    "                trade_result['exit_time'] = row['time']\n",
    "                trade_result['exit_price'] = profit_price\n",
    "                trade_result['exit_reason'] = 'Target Hit'\n",
    "                break\n",
    "            if row['low'] <= stop_price:\n",
    "                trade_result['exit_time'] = row['time']\n",
    "                trade_result['exit_price'] = stop_price\n",
    "                trade_result['exit_reason'] = 'Stop Loss Hit'\n",
    "                break\n",
    "            if carry_over and 'Normalized VOLD Ratio' in row and row['Normalized VOLD Ratio'] < 0:\n",
    "                trade_result['exit_time'] = row['time']\n",
    "                trade_result['exit_price'] = row['close']\n",
    "                trade_result['exit_reason'] = 'VOLD Cross Below 0'\n",
    "                break\n",
    "        else:\n",
    "            # If no target or stop loss hit, exit at the last price of the day\n",
    "            trade_result['exit_reason'] = 'End of Day Exit'\n",
    "            if not subsequent_data.empty:\n",
    "                last_row = subsequent_data.iloc[-1]\n",
    "                trade_result['exit_time'] = last_row['time']\n",
    "                trade_result['exit_price'] = last_row['close']\n",
    "        \n",
    "        if trade_result['exit_price'] is not None:\n",
    "            quantity = 25 if 'NIFTY' in symbol else 15 if 'BANKNIFTY' in symbol else 40 if 'FINNIFTY' in symbol else 10\n",
    "            gross_profit = (trade_result['exit_price'] - trade_result['entry_price']) * quantity\n",
    "            charges = calculate_charges(trade_result['entry_price'], trade_result['exit_price'], quantity)\n",
    "            net_profit = gross_profit - charges\n",
    "            trade_result['charges'] = charges\n",
    "            trade_result['profit_before_charges'] = gross_profit\n",
    "            trade_result['profit'] = net_profit\n",
    "\n",
    "        results.append(trade_result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    if results_df.empty:\n",
    "        print(\"No trades were executed.\")\n",
    "        return pd.DataFrame(columns=['signal_time', 'entry_time', 'entry_price', 'Target Profit', 'Stop Loss', \n",
    "                                     'Profit Price', 'Stop Price', 'exit_time', 'exit_price', 'charges', \n",
    "                                     'profit_before_charges', 'profit', 'exit_reason', 'SOSI', \n",
    "                                     'Normalized VOLD Ratio', 'Normalized Theta'])\n",
    "    \n",
    "    return results_df.dropna(subset=['entry_price'])\n",
    "\n",
    "# Function to analyze profit and stop loss percentages\n",
    "def analyze_profit_and_stop_loss(buy_signals, minute_data, folder_name, profit_percentages, stop_loss_percentages, min_stop_loss=0.005, error_margin=0.01, carry_over=False):\n",
    "    analysis_results = []\n",
    "    finalresults = []\n",
    "    for profit_target in profit_percentages:\n",
    "        for stop_loss in stop_loss_percentages:\n",
    "            trade_results = simulate_day_trades(buy_signals, minute_data, folder_name, profit_target, stop_loss, min_stop_loss, error_margin, carry_over=carry_over)\n",
    "            if not trade_results.empty:\n",
    "                total_profit = trade_results['profit'].sum()\n",
    "                charges = trade_results['charges'].sum()\n",
    "                trade_time=trade_results['signal_time']\n",
    "                profit_before_charges = trade_results['profit_before_charges'].sum()\n",
    "                analysis_results.append((trade_time,profit_target, stop_loss, charges, profit_before_charges, total_profit))\n",
    "                finalresults.append(trade_results)\n",
    "    # Combine all trade results into a single DataFrame\n",
    "    if finalresults:\n",
    "        combined_trade_results = pd.concat(finalresults, ignore_index=True)\n",
    "    else:\n",
    "        combined_trade_results = pd.DataFrame(columns=['signal_time', 'entry_time', 'entry_price', 'Target Profit', \n",
    "                                                       'Stop Loss', 'Profit Price', 'Stop Price', 'exit_time', \n",
    "                                                       'exit_price', 'charges', 'profit_before_charges', 'profit', \n",
    "                                                       'exit_reason', 'SOSI', 'Normalized VOLD Ratio', 'Normalized Theta'])\n",
    " \n",
    "    return pd.DataFrame(analysis_results, columns=['Signal Time','Profit Target', 'Stop Loss', 'Charges', 'Profit Before Charges', 'Total Profit']), combined_trade_results\n",
    "\n",
    "# Function to summarize trade results\n",
    "def summarize_trade_results(trade_results):\n",
    "    total_trades = len(trade_results)\n",
    "    target_hit = len(trade_results[trade_results['exit_reason'] == 'Target Hit'])\n",
    "    stop_loss_hit = len(trade_results[trade_results['exit_reason'] == 'Stop Loss Hit'])\n",
    "    end_of_day_exit = len(trade_results[trade_results['exit_reason'] == 'End of Day Exit'])\n",
    "    max_drawdown = trade_results['profit'].min() if not trade_results.empty else 0\n",
    "    summary = {\n",
    "        'Total Trades': total_trades,\n",
    "        'Target Hit': target_hit,\n",
    "        'Stop Loss Hit': stop_loss_hit,\n",
    "        'End of Day Exit': end_of_day_exit,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Define profit percentages and stop loss percentages to analyze\n",
    "profit_percentages = [i / 100 for i in range(1, 200)]\n",
    "stop_loss_percentages = [i / 100 for i in range(1, 20)]\n",
    "profit_percentages_carryover = [i / 100 for i in range(1, 1000)]\n",
    "stop_loss_percentages_carryover = [i / 100 for i in range(1, 20)]\n",
    "\n",
    "# Directories containing the data\n",
    "directories = ['June 2024/NIFTY', 'June 2024/BANKNIFTY', 'June 2024/FINNIFTY']  # Change the directories as needed\n",
    "\n",
    "# Function to check if the date is within the week of expiration\n",
    "def is_within_expiry_week(expiry_date, timestamp, folder_name, days_before_expiry=5):\n",
    "    # Assuming the date is the 7th to 12th characters in the string\n",
    "    if folder_name == 'NIFTY':\n",
    "        date_part = expiry_date[9:15]\n",
    "    if folder_name == 'BANKNIFTY':\n",
    "        date_part = expiry_date[13:19]\n",
    "    if folder_name == 'FINNIFTY':\n",
    "        date_part = expiry_date[12:18]\n",
    "    if folder_name == 'SENSEX':\n",
    "        date_part = expiry_date[7:13]\n",
    "    \n",
    "    expiry_datetime = pd.to_datetime(date_part, format='%y%m%d')\n",
    "    signal_datetime = pd.to_datetime(timestamp, unit='s')\n",
    "    return (expiry_datetime - signal_datetime).days <= days_before_expiry\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    pnl_results_below_9_30 = []\n",
    "    pnl_results_eod = []\n",
    "    pnl_results_carry_over = []\n",
    "    trade_results_combined_below_9_30 = []\n",
    "    trade_results_combined_eod = []\n",
    "    trade_results_combined_carry_over = []\n",
    "    all_combined_results_below_9_30 = []\n",
    "    all_combined_results_eod = []\n",
    "    all_combined_results_carry_over = []\n",
    "    folder_name = os.path.basename(directory)\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        if subdir == directory:\n",
    "            continue  # Skip the top-level directory itself\n",
    "        for filename in files:\n",
    "            if ', 5.csv' in filename:\n",
    "                minute_5_path = os.path.join(subdir, filename)\n",
    "                minute_1_path = minute_5_path.replace(', 5.csv', ', 1.csv')\n",
    "                \n",
    "                if os.path.exists(minute_1_path):\n",
    "                    print(f\"Processing {filename} in {folder_name}...\")\n",
    "                    \n",
    "                    # Extract expiry date from filename\n",
    "                    expiry_date = filename.split(' ')[0].split(',')[0]\n",
    "                    \n",
    "                    # Load the CSV files\n",
    "                    minute_data_5 = pd.read_csv(minute_5_path)\n",
    "                    minute_data_1 = pd.read_csv(minute_1_path)\n",
    "                    \n",
    "                    # Scenario 1: Filter buy signals before 9:30 AM IST\n",
    "                    buy_signals_below_9_30 = filter_signals_vold_crossover(minute_data_5, time_limit=datetime.strptime('09:30:00', '%H:%M:%S').time())\n",
    "                    if buy_signals_below_9_30 is None or buy_signals_below_9_30.empty:\n",
    "                        print(f\"No buy signals found before 9:30 AM IST for {filename}. Skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Scenario 2: Filter buy signals with no time limit\n",
    "                    buy_signals_no_time_limit = filter_signals_vold_crossover(minute_data_5)\n",
    "                    if buy_signals_no_time_limit is None or buy_signals_no_time_limit.empty:\n",
    "                        print(f\"No buy signals found for {filename}. Skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Perform the analysis for each scenario\n",
    "                    # Scenario 1: Below 9:30 AM IST\n",
    "                    analysis_results_below_9_30, trade_results_below_9_30 = analyze_profit_and_stop_loss(\n",
    "                        buy_signals_below_9_30, minute_data_1, folder_name, profit_percentages, stop_loss_percentages\n",
    "                    )\n",
    "                    combined_results_below_9_30 = pd.merge(buy_signals_below_9_30, trade_results_below_9_30, left_on='time', right_on='signal_time', how='inner')\n",
    "                    combined_results_below_9_30 = pd.merge(combined_results_below_9_30, minute_data_5, left_on='time', right_on='time', suffixes=('_buy', '_original'))\n",
    "                    all_combined_results_below_9_30.append(combined_results_below_9_30)\n",
    "                    pnl_results_below_9_30.append(analysis_results_below_9_30)\n",
    "                    trade_results_combined_below_9_30.append(trade_results_below_9_30)\n",
    "                    \n",
    "                    # Scenario 2: End of day exits\n",
    "                    analysis_results_eod, trade_results_eod = analyze_profit_and_stop_loss(\n",
    "                        buy_signals_no_time_limit, minute_data_1, folder_name, profit_percentages, stop_loss_percentages\n",
    "                    )\n",
    "                    combined_results_eod = pd.merge(buy_signals_no_time_limit, trade_results_eod, left_on='time', right_on='signal_time', how='inner')\n",
    "                    combined_results_eod = pd.merge(combined_results_eod, minute_data_5, left_on='time', right_on='time', suffixes=('_buy', '_original'))\n",
    "                    all_combined_results_eod.append(combined_results_eod)\n",
    "                    pnl_results_eod.append(analysis_results_eod)\n",
    "                    trade_results_combined_eod.append(trade_results_eod)\n",
    "                    \n",
    "                    # Scenario 3: Carry over trades\n",
    "                    analysis_results_carry_over, trade_results_carry_over = analyze_profit_and_stop_loss(\n",
    "                        buy_signals_no_time_limit, minute_data_1, folder_name, profit_percentages_carryover, stop_loss_percentages_carryover, carry_over=True\n",
    "                    )\n",
    "                    combined_results_carry_over = pd.merge(buy_signals_no_time_limit, trade_results_carry_over, left_on='time', right_on='signal_time', how='inner')\n",
    "                    combined_results_carry_over = pd.merge(combined_results_carry_over, minute_data_5, left_on='time', right_on='time', suffixes=('_buy', '_original'))\n",
    "                    all_combined_results_carry_over.append(combined_results_carry_over)\n",
    "                    pnl_results_carry_over.append(analysis_results_carry_over)\n",
    "                    trade_results_combined_carry_over.append(trade_results_carry_over)\n",
    "\n",
    "    # Combine and save results for signals before 9:30 AM IST\n",
    "    if pnl_results_below_9_30:\n",
    "        combined_pnl_results_below_9_30 = pd.concat(pnl_results_below_9_30, ignore_index=True)\n",
    "        combined_pnl_results_below_9_30 = combined_pnl_results_below_9_30.groupby(['Profit Target', 'Stop Loss'], as_index=False)['Total Profit'].sum()\n",
    "        combined_trade_results_below_9_30 = pd.concat(trade_results_combined_below_9_30, ignore_index=True)\n",
    "        combined_all_results_below_9_30 = pd.concat(all_combined_results_below_9_30, ignore_index=True)\n",
    "\n",
    "        output_dir_below_9_30 = f'Outputs/DayTrade/SOSI/5min/{folder_name}_below_9_30'\n",
    "        os.makedirs(output_dir_below_9_30, exist_ok=True)\n",
    "        \n",
    "        combined_pnl_results_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_pnl_analysis.csv', index=False)\n",
    "        combined_trade_results_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_trade_results.csv', index=False)\n",
    "        combined_all_results_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_all_combined_results.csv', index=False)\n",
    "        \n",
    "        best_combination_below_9_30 = combined_pnl_results_below_9_30.loc[combined_pnl_results_below_9_30['Total Profit'].idxmax()]\n",
    "        best_combination_df_below_9_30 = pd.DataFrame([best_combination_below_9_30])\n",
    "        best_combination_df_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_best_combination.csv', index=False)\n",
    "        \n",
    "        top_40_combinations_below_9_30 = combined_pnl_results_below_9_30.sort_values(by='Total Profit', ascending=False).head(40)\n",
    "        top_40_combinations_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_top_40_combinations.csv', index=False)\n",
    "        \n",
    "        best_trade_results_below_9_30 = combined_trade_results_below_9_30[(combined_trade_results_below_9_30['Target Profit'] == best_combination_below_9_30['Profit Target']) & \n",
    "                                                                         (combined_trade_results_below_9_30['Stop Loss'] == best_combination_below_9_30['Stop Loss'])]\n",
    "        trade_summary_below_9_30 = summarize_trade_results(best_trade_results_below_9_30)\n",
    "        trade_summary_df_below_9_30 = pd.DataFrame([trade_summary_below_9_30])\n",
    "        trade_summary_df_below_9_30.to_csv(f'{output_dir_below_9_30}/{folder_name}_trade_summary.csv', index=False)\n",
    "        \n",
    "        labels = ['Target Hit', 'Stop Loss Hit', 'End of Day Exit']\n",
    "        sizes = [trade_summary_below_9_30['Target Hit'], trade_summary_below_9_30['Stop Loss Hit'], trade_summary_below_9_30['End of Day Exit']]\n",
    "        colors = ['lightgreen', 'lightcoral', 'lightskyblue']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "        plt.title(f'Trade Summary for Best PNL Combination (Before 9:30 AM)\\n{folder_name}')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_below_9_30}/{folder_name}_trade_summary_pie_chart.png')\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Total Trades'], [trade_summary_below_9_30['Total Trades']], color='skyblue')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Total Trades')\n",
    "        plt.title(f'Total Trades for Best PNL Combination (Before 9:30 AM)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_below_9_30}/{folder_name}_total_trades_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Max Drawdown'], [trade_summary_below_9_30['Max Drawdown']], color='red')\n",
    "        plt.xlabel('Max Drawdown')\n",
    "        plt.ylabel('Max Drawdown Value')\n",
    "        plt.title(f'Max Drawdown for Best PNL Combination (Before 9:30 AM)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_below_9_30}/{folder_name}_max_drawdown_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(top_40_combinations_below_9_30['Profit Target'].astype(str) + \" / \" + top_40_combinations_below_9_30['Stop Loss'].astype(str),\n",
    "                 top_40_combinations_below_9_30['Total Profit'], color='skyblue')\n",
    "        plt.xlabel('Total Profit')\n",
    "        plt.ylabel('Profit Target / Stop Loss')\n",
    "        plt.title(f'Top 40 Profit Target and Stop Loss Combinations (Before 9:30 AM)\\n{folder_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_below_9_30}/{folder_name}_top_40_combinations.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Combine and save results for end of day exits\n",
    "    if pnl_results_eod:\n",
    "        combined_pnl_results_eod = pd.concat(pnl_results_eod, ignore_index=True)\n",
    "        combined_pnl_results_eod = combined_pnl_results_eod.groupby(['Profit Target', 'Stop Loss'], as_index=False)['Total Profit'].sum()\n",
    "        combined_trade_results_eod = pd.concat(trade_results_combined_eod, ignore_index=True)\n",
    "        combined_all_results_eod = pd.concat(all_combined_results_eod, ignore_index=True)\n",
    "\n",
    "        output_dir_eod = f'Outputs/DayTrade/SOSI/5min/{folder_name}_eod'\n",
    "        os.makedirs(output_dir_eod, exist_ok=True)\n",
    "        \n",
    "        combined_pnl_results_eod.to_csv(f'{output_dir_eod}/{folder_name}_pnl_analysis.csv', index=False)\n",
    "        combined_trade_results_eod.to_csv(f'{output_dir_eod}/{folder_name}_trade_results.csv', index=False)\n",
    "        combined_all_results_eod.to_csv(f'{output_dir_eod}/{folder_name}_all_combined_results.csv', index=False)\n",
    "        \n",
    "        best_combination_eod = combined_pnl_results_eod.loc[combined_pnl_results_eod['Total Profit'].idxmax()]\n",
    "        best_combination_df_eod = pd.DataFrame([best_combination_eod])\n",
    "        best_combination_df_eod.to_csv(f'{output_dir_eod}/{folder_name}_best_combination.csv', index=False)\n",
    "        \n",
    "        top_40_combinations_eod = combined_pnl_results_eod.sort_values(by='Total Profit', ascending=False).head(40)\n",
    "        top_40_combinations_eod.to_csv(f'{output_dir_eod}/{folder_name}_top_40_combinations.csv', index=False)\n",
    "        \n",
    "        best_trade_results_eod = combined_trade_results_eod[(combined_trade_results_eod['Target Profit'] == best_combination_eod['Profit Target']) & \n",
    "                                                            (combined_trade_results_eod['Stop Loss'] == best_combination_eod['Stop Loss'])]\n",
    "        trade_summary_eod = summarize_trade_results(best_trade_results_eod)\n",
    "        trade_summary_df_eod = pd.DataFrame([trade_summary_eod])\n",
    "        trade_summary_df_eod.to_csv(f'{output_dir_eod}/{folder_name}_trade_summary.csv', index=False)\n",
    "        \n",
    "        labels = ['Target Hit', 'Stop Loss Hit', 'End of Day Exit']\n",
    "        sizes = [trade_summary_eod['Target Hit'], trade_summary_eod['Stop Loss Hit'], trade_summary_eod['End of Day Exit']]\n",
    "        colors = ['lightgreen', 'lightcoral', 'lightskyblue']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "        plt.title(f'Trade Summary for Best PNL Combination (EOD)\\n{folder_name}')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_eod}/{folder_name}_trade_summary_pie_chart.png')\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Total Trades'], [trade_summary_eod['Total Trades']], color='skyblue')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Total Trades')\n",
    "        plt.title(f'Total Trades for Best PNL Combination (EOD)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_eod}/{folder_name}_total_trades_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Max Drawdown'], [trade_summary_eod['Max Drawdown']], color='red')\n",
    "        plt.xlabel('Max Drawdown')\n",
    "        plt.ylabel('Max Drawdown Value')\n",
    "        plt.title(f'Max Drawdown for Best PNL Combination (EOD)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_eod}/{folder_name}_max_drawdown_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(top_40_combinations_eod['Profit Target'].astype(str) + \" / \" + top_40_combinations_eod['Stop Loss'].astype(str),\n",
    "                 top_40_combinations_eod['Total Profit'], color='skyblue')\n",
    "        plt.xlabel('Total Profit')\n",
    "        plt.ylabel('Profit Target / Stop Loss')\n",
    "        plt.title(f'Top 40 Profit Target and Stop Loss Combinations (EOD)\\n{folder_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_eod}/{folder_name}_top_40_combinations.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Combine and save results for carry over trades\n",
    "    if pnl_results_carry_over:\n",
    "        combined_pnl_results_carry_over = pd.concat(pnl_results_carry_over, ignore_index=True)\n",
    "        combined_pnl_results_carry_over = combined_pnl_results_carry_over.groupby(['Profit Target', 'Stop Loss'], as_index=False)['Total Profit'].sum()\n",
    "        combined_trade_results_carry_over = pd.concat(trade_results_combined_carry_over, ignore_index=True)\n",
    "        combined_all_results_carry_over = pd.concat(all_combined_results_carry_over, ignore_index=True)\n",
    "\n",
    "        output_dir_carry_over = f'Outputs/DayTrade/SOSI/5min/{folder_name}_carry_over'\n",
    "        os.makedirs(output_dir_carry_over, exist_ok=True)\n",
    "        \n",
    "        combined_pnl_results_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_pnl_analysis.csv', index=False)\n",
    "        combined_trade_results_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_trade_results.csv', index=False)\n",
    "        combined_all_results_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_all_combined_results.csv', index=False)\n",
    "        \n",
    "        best_combination_carry_over = combined_pnl_results_carry_over.loc[combined_pnl_results_carry_over['Total Profit'].idxmax()]\n",
    "        best_combination_df_carry_over = pd.DataFrame([best_combination_carry_over])\n",
    "        best_combination_df_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_best_combination.csv', index=False)\n",
    "        \n",
    "        top_40_combinations_carry_over = combined_pnl_results_carry_over.sort_values(by='Total Profit', ascending=False).head(40)\n",
    "        top_40_combinations_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_top_40_combinations.csv', index=False)\n",
    "        \n",
    "        best_trade_results_carry_over = combined_trade_results_carry_over[(combined_trade_results_carry_over['Target Profit'] == best_combination_carry_over['Profit Target']) & \n",
    "                                                                          (combined_trade_results_carry_over['Stop Loss'] == best_combination_carry_over['Stop Loss'])]\n",
    "        trade_summary_carry_over = summarize_trade_results(best_trade_results_carry_over)\n",
    "        trade_summary_df_carry_over = pd.DataFrame([trade_summary_carry_over])\n",
    "        trade_summary_df_carry_over.to_csv(f'{output_dir_carry_over}/{folder_name}_trade_summary.csv', index=False)\n",
    "        \n",
    "        labels = ['Target Hit', 'Stop Loss Hit', 'End of Day Exit']\n",
    "        sizes = [trade_summary_carry_over['Target Hit'], trade_summary_carry_over['Stop Loss Hit'], trade_summary_carry_over['End of Day Exit']]\n",
    "        colors = ['lightgreen', 'lightcoral', 'lightskyblue']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "        plt.title(f'Trade Summary for Best PNL Combination (Carry Over)\\n{folder_name}')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_carry_over}/{folder_name}_trade_summary_pie_chart.png')\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Total Trades'], [trade_summary_carry_over['Total Trades']], color='skyblue')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Total Trades')\n",
    "        plt.title(f'Total Trades for Best PTotal Trades for Best PNL Combination (Carry Over)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_carry_over}/{folder_name}_total_trades_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Max Drawdown'], [trade_summary_carry_over['Max Drawdown']], color='red')\n",
    "        plt.xlabel('Max Drawdown')\n",
    "        plt.ylabel('Max Drawdown Value')\n",
    "        plt.title(f'Max Drawdown for Best PNL Combination (Carry Over)\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_carry_over}/{folder_name}_max_drawdown_bar_chart.png')\n",
    "        plt.close()\n",
    "    \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(top_40_combinations_carry_over['Profit Target'].astype(str) + \" / \" + top_40_combinations_carry_over['Stop Loss'].astype(str),\n",
    "                 top_40_combinations_carry_over['Total Profit'], color='skyblue')\n",
    "        plt.xlabel('Total Profit')\n",
    "        plt.ylabel('Profit Target / Stop Loss')\n",
    "        plt.title(f'Top 40 Profit Target and Stop Loss Combinations (Carry Over)\\n{folder_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir_carry_over}/{folder_name}_top_40_combinations.png')\n",
    "        plt.close()\n",
    "\n",
    "print(\"Analysis complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
