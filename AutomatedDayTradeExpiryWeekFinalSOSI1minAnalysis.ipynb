{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to identify best target profit and stop loss combination for SOSI Final Version, which only provides signal at 9:20 AM everyday and provides accurate update on whether the trade should be taken or not.\n",
    "\n",
    "This contains all sosi values and all plots used for calculating the buy signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to filter buy signals from the 1-minute chart data\n",
    "def filter_signals(data):\n",
    "    if 'Buy Signal SOSI Final' not in data.columns:\n",
    "        print(\"Warning: 'Buy Signal SOSI Final' column not found in the data.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the column is not found\n",
    "    buy_signals = data[(data['Buy Signal SOSI Final'] == True)]\n",
    "    return buy_signals\n",
    "\n",
    "# Function to calculate charges\n",
    "def calculate_charges(entry_price, exit_price, quantity):\n",
    "    brokerage = 40  # total brokerage for one complete buy and sell\n",
    "    stt_ctt = 0.00125 * exit_price * quantity\n",
    "    transaction_charges = 0.000495 * (entry_price + exit_price) * quantity\n",
    "    gst = 0.18 * (brokerage + transaction_charges)\n",
    "    sebi_charges = 10 / 10**7 * (entry_price + exit_price) * quantity\n",
    "    stamp_charges = 0.00003 * entry_price * quantity\n",
    "    total_charges = brokerage + stt_ctt + transaction_charges + gst + sebi_charges + stamp_charges\n",
    "    return total_charges\n",
    "\n",
    "# Function to simulate day trades with error margin\n",
    "def simulate_day_trades(buy_signals, minute_data, symbol, profit_target=0.02, stop_loss=0.01, min_stop_loss=0.005, error_margin=0.03):\n",
    "    results = []\n",
    "\n",
    "    for index, buy_signal in buy_signals.iterrows():\n",
    "        entry_price = buy_signal['close'] * (1 + error_margin)  # Adjust entry price with error margin\n",
    "        entry_time = buy_signal['time'] + 60  # Add 1 minute to the buy signal time to get the entry time\n",
    "\n",
    "        # Convert entry_time from epoch to datetime\n",
    "        entry_datetime = pd.to_datetime(entry_time, unit='s')\n",
    "        entry_datetime_ist = entry_datetime + timedelta(hours=5, minutes=30)  # Convert to IST\n",
    "        \n",
    "        # Check if the entry time is post 2:30 PM IST\n",
    "        if entry_datetime_ist.time() >= datetime.strptime('14:30:00', '%H:%M:%S').time():\n",
    "            continue  # Skip trades initiated after 2:30 PM IST\n",
    "\n",
    "        profit_price = entry_price * (1 + profit_target)\n",
    "        stop_price = entry_price * (1 - max(stop_loss, min_stop_loss))  # Ensure stop loss is at least min_stop_loss\n",
    "        \n",
    "        trade_result = {\n",
    "            'signal_time': buy_signal['time'],\n",
    "            'entry_time': entry_time,\n",
    "            'entry_price': entry_price,\n",
    "            'Target Profit': profit_target,\n",
    "            'Stop Loss': stop_loss,\n",
    "            'Profit Price': profit_price,\n",
    "            'Stop Price': stop_price,\n",
    "            'exit_time': None,\n",
    "            'exit_price': None,\n",
    "            'charges': None,\n",
    "            'profit_before_charges': None,\n",
    "            'profit': None,\n",
    "            'exit_reason': None,\n",
    "            'SOSI': buy_signal.get('SOSI'),\n",
    "            'Normalized VOLD Ratio': buy_signal.get('Normalized VOLD Ratio'),\n",
    "            'Normalized Theta': buy_signal.get('Normalized Theta')\n",
    "        }\n",
    "        \n",
    "        # Filter subsequent data for the same day only\n",
    "        trade_date = pd.to_datetime(entry_time, unit='s').date()\n",
    "        subsequent_data = minute_data[(minute_data['time'] > entry_time) & \n",
    "                                      (pd.to_datetime(minute_data['time'], unit='s').dt.date == trade_date)]\n",
    "        \n",
    "        for _, row in subsequent_data.iterrows():\n",
    "            if row['high'] >= profit_price:\n",
    "                trade_result['exit_time'] = row['time']\n",
    "                trade_result['exit_price'] = profit_price\n",
    "                trade_result['exit_reason'] = 'Target Hit'\n",
    "                break\n",
    "            if row['low'] <= stop_price:\n",
    "                trade_result['exit_time'] = row['time']\n",
    "                trade_result['exit_price'] = stop_price\n",
    "                trade_result['exit_reason'] = 'Stop Loss Hit'\n",
    "                break\n",
    "        else:\n",
    "            # If no target or stop loss hit, exit at the last price of the day\n",
    "            trade_result['exit_reason'] = 'End of Day Exit'\n",
    "            if not subsequent_data.empty:\n",
    "                last_row = subsequent_data.iloc[-1]\n",
    "                trade_result['exit_time'] = last_row['time']\n",
    "                trade_result['exit_price'] = last_row['close']\n",
    "        \n",
    "        if trade_result['exit_price'] is not None:\n",
    "            quantity = 25 if 'NIFTY' in symbol else 15 if 'BANKNIFTY' in symbol else 40 if 'FINNIFTY' in symbol else 10\n",
    "            gross_profit = (trade_result['exit_price'] - trade_result['entry_price']) * quantity\n",
    "            charges = calculate_charges(trade_result['entry_price'], trade_result['exit_price'], quantity)\n",
    "            net_profit = gross_profit - charges\n",
    "            trade_result['charges'] = charges\n",
    "            trade_result['profit_before_charges'] = gross_profit\n",
    "            trade_result['profit'] = net_profit\n",
    "\n",
    "        results.append(trade_result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    if results_df.empty:\n",
    "        print(\"No trades were executed before 2:30 PM IST.\")\n",
    "        return pd.DataFrame(columns=['signal_time', 'entry_time', 'entry_price', 'Target Profit', 'Stop Loss', \n",
    "                                     'Profit Price', 'Stop Price', 'exit_time', 'exit_price', 'charges', \n",
    "                                     'profit_before_charges', 'profit', 'exit_reason', 'SOSI', \n",
    "                                     'Normalized VOLD Ratio', 'Normalized Theta'])\n",
    "    \n",
    "    return results_df.dropna(subset=['entry_price'])\n",
    "\n",
    "# Function to analyze profit and stop loss percentages\n",
    "def analyze_profit_and_stop_loss(buy_signals, minute_data, profit_percentages, stop_loss_percentages, min_stop_loss=0.005, error_margin=0.01):\n",
    "    analysis_results = []\n",
    "    finalresults = []\n",
    "    for profit_target in profit_percentages:\n",
    "        for stop_loss in stop_loss_percentages:\n",
    "            trade_results = simulate_day_trades(buy_signals, minute_data, folder_name, profit_target, stop_loss, min_stop_loss, error_margin)\n",
    "            total_profit = trade_results['profit'].sum()\n",
    "            charges = trade_results['charges'].sum()\n",
    "            profit_before_charges = trade_results['profit_before_charges'].sum()\n",
    "            analysis_results.append((profit_target, stop_loss, charges, profit_before_charges, total_profit))\n",
    "            finalresults.append(trade_results)\n",
    "    # Combine all trade results into a single DataFrame\n",
    "    combined_trade_results = pd.concat(finalresults, ignore_index=True)\n",
    " \n",
    "    return pd.DataFrame(analysis_results, columns=['Profit Target', 'Stop Loss', 'Charges', 'Profit Before Charges', 'Total Profit']), combined_trade_results\n",
    "\n",
    "# Function to summarize trade results\n",
    "def summarize_trade_results(trade_results):\n",
    "    total_trades = len(trade_results)\n",
    "    target_hit = len(trade_results[trade_results['exit_reason'] == 'Target Hit'])\n",
    "    stop_loss_hit = len(trade_results[trade_results['exit_reason'] == 'Stop Loss Hit'])\n",
    "    end_of_day_exit = len(trade_results[trade_results['exit_reason'] == 'End of Day Exit'])\n",
    "    max_drawdown = trade_results['profit'].min()\n",
    "    summary = {\n",
    "        'Total Trades': total_trades,\n",
    "        'Target Hit': target_hit,\n",
    "        'Stop Loss Hit': stop_loss_hit,\n",
    "        'End of Day Exit': end_of_day_exit,\n",
    "        'Max Drawdown': max_drawdown\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "# Define profit percentages and stop loss percentages to analyze\n",
    "profit_percentages = [i / 100 for i in range(1, 200)]\n",
    "stop_loss_percentages = [i / 100 for i in range(1, 15)]\n",
    "\n",
    "# Directories containing the data\n",
    "directories = ['June 2024/NIFTY', 'June 2024/BANKNIFTY', 'June 2024/FINNIFTY']  # Change the directories as needed\n",
    "\n",
    "# Function to check if the date is within the week of expiration\n",
    "def is_within_expiry_week(expiry_date, timestamp, folder_name, days_before_expiry=5):\n",
    "    # Assuming the date is the 7th to 12th characters in the string\n",
    "    if folder_name == 'NIFTY':\n",
    "        date_part = expiry_date[9:15]\n",
    "    if folder_name == 'BANKNIFTY':\n",
    "        date_part = expiry_date[13:19]\n",
    "    if folder_name == 'FINNIFTY':\n",
    "        date_part = expiry_date[12:18]\n",
    "    if folder_name == 'SENSEX':\n",
    "        date_part = expiry_date[7:13]\n",
    "    \n",
    "    expiry_datetime = pd.to_datetime(date_part, format='%y%m%d')\n",
    "    signal_datetime = pd.to_datetime(timestamp, unit='s')\n",
    "    return (expiry_datetime - signal_datetime).days <= days_before_expiry\n",
    "\n",
    "# Process each directory\n",
    "for directory in directories:\n",
    "    pnl_results = []\n",
    "    trade_results_combined = []\n",
    "    all_combined_results = []\n",
    "    folder_name = os.path.basename(directory)\n",
    "    for subdir, _, files in os.walk(directory):\n",
    "        if subdir == directory:\n",
    "            continue  # Skip the top-level directory itself\n",
    "        for filename in files:\n",
    "            if ', 1.csv' in filename:  # Change to ', 1.csv' for 1-minute data\n",
    "                minute_1_path = os.path.join(subdir, filename)\n",
    "                \n",
    "                if os.path.exists(minute_1_path):\n",
    "                    print(f\"Processing {filename} in {folder_name}...\")\n",
    "                    \n",
    "                    # Extract expiry date from filename\n",
    "                    expiry_date = filename.split(' ')[0].split(',')[0]\n",
    "                    \n",
    "                    # Load the CSV file\n",
    "                    minute_data_1 = pd.read_csv(minute_1_path)\n",
    "                    \n",
    "                    # Filter buy signals\n",
    "                    buy_signals = filter_signals(minute_data_1)\n",
    "\n",
    "                    # Skip if no buy signals\n",
    "                    if buy_signals.empty:\n",
    "                        print(f\"No buy signals found for {filename}. Skipping...\")\n",
    "                        continue\n",
    "                    # Filter signals to only include those within the expiry week\n",
    "                    buy_signals = buy_signals[buy_signals['time'].apply(lambda x: is_within_expiry_week(expiry_date, x, folder_name))]\n",
    "                    \n",
    "                    # Skip if no buy signals within expiry week\n",
    "                    if buy_signals.empty:\n",
    "                        print(f\"No buy signals found within expiry week for {filename}. Skipping...\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Perform the analysis\n",
    "                    analysis_results, trade_results = analyze_profit_and_stop_loss(buy_signals, minute_data_1, profit_percentages, stop_loss_percentages)\n",
    "                    \n",
    "                    # Merge buy signals with trade results\n",
    "                    combined_results = pd.merge(buy_signals, trade_results, left_on='time', right_on='signal_time', how='inner')\n",
    "                    \n",
    "                    # Merge the 1-minute chart data with combined results\n",
    "                    combined_results = pd.merge(combined_results, minute_data_1, left_on='time', right_on='time', suffixes=('_buy', '_original'))\n",
    "                   \n",
    "                    all_combined_results.append(combined_results)\n",
    "                    \n",
    "                    # Append to combined results\n",
    "                    pnl_results.append(analysis_results)\n",
    "                    trade_results_combined.append(trade_results)\n",
    "    \n",
    "    # Combine all results for the folder\n",
    "    if not pnl_results:\n",
    "        print(f\"No data found for {folder_name}. Skipping...\")\n",
    "        continue    \n",
    "    combined_pnl_results = pd.concat(pnl_results, ignore_index=True)\n",
    "    # Aggregate total profits for the same combinations\n",
    "    combined_pnl_results = combined_pnl_results.groupby(['Profit Target', 'Stop Loss'], as_index=False)['Total Profit'].sum()\n",
    "    combined_trade_results = pd.concat(trade_results_combined, ignore_index=True)\n",
    "    combined_all_results = pd.concat(all_combined_results, ignore_index=True)\n",
    "    \n",
    "    # Save the results to CSV files\n",
    "    output_dir = f'Outputs/DayTrade/SOSI/1min/{folder_name}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    combined_pnl_results.to_csv(f'{output_dir}/{folder_name}_pnl_analysis.csv', index=False)\n",
    "    combined_trade_results.to_csv(f'{output_dir}/{folder_name}_trade_results.csv', index=False)\n",
    "    combined_all_results.to_csv(f'{output_dir}/{folder_name}_all_combined_results.csv', index=False)\n",
    "    \n",
    "    # Find the best combination of profit target and stop loss\n",
    "    if not combined_pnl_results.empty:\n",
    "        best_combination = combined_pnl_results.loc[combined_pnl_results['Total Profit'].idxmax()]\n",
    "        \n",
    "        # Save the best combination\n",
    "        best_combination_df = pd.DataFrame([best_combination])\n",
    "        best_combination_df.to_csv(f'{output_dir}/{folder_name}_best_combination.csv', index=False)\n",
    "        \n",
    "        # Save the top 40 combinations\n",
    "        top_40_combinations = combined_pnl_results.sort_values(by='Total Profit', ascending=False).head(40)\n",
    "        top_40_combinations.to_csv(f'{output_dir}/{folder_name}_top_40_combinations.csv', index=False)\n",
    "        \n",
    "        # Filter the best trade results from the combined trade results\n",
    "        best_trade_results = combined_trade_results[(combined_trade_results['Target Profit'] == best_combination['Profit Target']) & \n",
    "                                                    (combined_trade_results['Stop Loss'] == best_combination['Stop Loss'])]\n",
    "        \n",
    "        # Summarize the trade results for the best combination\n",
    "        trade_summary = summarize_trade_results(best_trade_results)\n",
    "        \n",
    "        # Save the trade summary\n",
    "        trade_summary_df = pd.DataFrame([trade_summary])\n",
    "        trade_summary_df.to_csv(f'{output_dir}/{folder_name}_trade_summary.csv', index=False)\n",
    "        \n",
    "        # Plot the pie chart for trade summary\n",
    "        labels = ['Target Hit', 'Stop Loss Hit', 'End of Day Exit']\n",
    "        sizes = [trade_summary['Target Hit'], trade_summary['Stop Loss Hit'], trade_summary['End of Day Exit']]\n",
    "        colors = ['lightgreen', 'lightcoral', 'lightskyblue']\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "        plt.title(f'Trade Summary for Best PNL Combination\\n{folder_name}')\n",
    "        plt.axis('equal')\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir}/{folder_name}_trade_summary_pie_chart.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot the bar chart for total trades\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Total Trades'], [trade_summary['Total Trades']], color='skyblue')\n",
    "        plt.xlabel('Count')\n",
    "        plt.ylabel('Total Trades')\n",
    "        plt.title(f'Total Trades for Best PNL Combination\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir}/{folder_name}_total_trades_bar_chart.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot the bar chart for max drawdown\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(['Max Drawdown'], [trade_summary['Max Drawdown']], color='red')\n",
    "        plt.xlabel('Max Drawdown')\n",
    "        plt.ylabel('Max Drawdown Value')\n",
    "        plt.title(f'Max Drawdown for Best PNL Combination\\n{folder_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir}/{folder_name}_max_drawdown_bar_chart.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot the heatmap for better visualization\n",
    "        pivot_table = combined_pnl_results.pivot(index=\"Stop Loss\", columns=\"Profit Target\", values=\"Total Profit\")\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar_kws={'label': 'Total Profit'})\n",
    "        plt.title(f\"Total Profit for Different Profit Targets and Stop Loss Percentages\\n{folder_name}\")\n",
    "        plt.xlabel(\"Profit Target\")\n",
    "        plt.ylabel(\"Stop Loss\")\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir}/{folder_name}_heatmap.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Plot the bar chart for the top 40 combinations\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(top_40_combinations['Profit Target'].astype(str) + \" / \" + top_40_combinations['Stop Loss'].astype(str),\n",
    "                 top_40_combinations['Total Profit'], color='skyblue')\n",
    "        plt.xlabel('Total Profit')\n",
    "        plt.ylabel('Profit Target / Stop Loss')\n",
    "        plt.title(f'Top 40 Profit Target and Stop Loss Combinations\\n{folder_name}')\n",
    "        plt.gca().invert_yaxis()  # To display the highest\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig(f'{output_dir}/{folder_name}_top_40_combinations.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Function to perform combined range analysis and plot the results\n",
    "        def combined_range_analysis():\n",
    "            indicators = ['SOSI', 'Normalized VOLD Ratio', 'Normalized Theta']\n",
    "            stop_loss_hits = combined_trade_results[combined_trade_results['exit_reason'] == 'Stop Loss Hit']\n",
    "            target_hits = combined_trade_results[combined_trade_results['exit_reason'] == 'Target Hit']\n",
    "            end_of_day_exits = combined_trade_results[combined_trade_results['exit_reason'] == 'End of Day Exit']\n",
    "        \n",
    "            if stop_loss_hits.empty and target_hits.empty and end_of_day_exits.empty:\n",
    "                print(\"No data available for combined range analysis.\")\n",
    "                return\n",
    "        \n",
    "            stop_loss_ranges = stop_loss_hits[indicators].apply(lambda x: (x.min(), x.max()), axis=0)\n",
    "            target_hit_ranges = target_hits[indicators].apply(lambda x: (x.min(), x.max()), axis=0)\n",
    "            end_of_day_exit_ranges = end_of_day_exits[indicators].apply(lambda x: (x.min(), x.max()), axis=0) if not end_of_day_exits.empty else pd.Series([(float('nan'), float('nan'))] * len(indicators), index=indicators)\n",
    "        \n",
    "            combined_data = {\n",
    "                'Indicator': indicators,\n",
    "                'Stop Loss Min': [rng[0] for rng in stop_loss_ranges],\n",
    "                'Stop Loss Max': [rng[1] for rng in stop_loss_ranges],\n",
    "                'Target Hit Min': [rng[0] for rng in target_hit_ranges],\n",
    "                'Target Hit Max': [rng[1] for rng in target_hit_ranges],\n",
    "                'End of Day Exit Min': [rng[0] for rng in end_of_day_exit_ranges],\n",
    "                'End of Day Exit Max': [rng[1] for rng in end_of_day_exit_ranges]\n",
    "            }\n",
    "        \n",
    "            combined_data_df = pd.DataFrame(combined_data)\n",
    "        \n",
    "            # Convert all relevant columns to numeric\n",
    "            for col in ['Stop Loss Min', 'Stop Loss Max', 'Target Hit Min', 'Target Hit Max', 'End of Day Exit Min', 'End of Day Exit Max']:\n",
    "                combined_data_df[col] = pd.to_numeric(combined_data_df[col], errors='coerce')\n",
    "            \n",
    "            # Ensure there is numeric data to plot\n",
    "            numeric_data = combined_data_df.drop(columns=['Indicator']).dropna(how='all', axis=1)\n",
    "            \n",
    "            if not numeric_data.empty and not combined_data_df.empty:\n",
    "                combined_data_df.set_index('Indicator').plot(kind='bar', figsize=(12, 8))\n",
    "                plt.title(f'Combined Range Analysis for Best PNL Combination\\n{folder_name}')\n",
    "                plt.ylabel('Range')\n",
    "                plt.show()\n",
    "                plt.savefig(f'{output_dir}/{folder_name}_combined_range_analysis.png')\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(\"No numeric data available for combined range analysis.\")\n",
    "        \n",
    "        # Call the function to perform the combined range analysis\n",
    "        combined_range_analysis()\n",
    "\n",
    "        def identify_ranges_to_avoid():\n",
    "            indicators = ['SOSI', 'Normalized VOLD Ratio', 'Normalized Theta']\n",
    "            stop_loss_hits = combined_trade_results[combined_trade_results['exit_reason'] == 'Stop Loss Hit']\n",
    "            target_hits = combined_trade_results[combined_trade_results['exit_reason'] == 'Target Hit']\n",
    "\n",
    "            \n",
    "            stop_loss_ranges = stop_loss_hits[indicators].apply(lambda x: (x.min(), x.max()), axis=0)\n",
    "            target_hit_ranges = target_hits[indicators].apply(lambda x: (x.min(), x.max()), axis=0)\n",
    "           \n",
    "            \n",
    "            combined_data = {\n",
    "                'Indicator': indicators,\n",
    "                'Stop Loss Min': stop_loss_ranges.apply(lambda x: x[0] if not pd.isna(x[0]) else None),\n",
    "                'Stop Loss Max': stop_loss_ranges.apply(lambda x: x[1] if not pd.isna(x[1]) else None),\n",
    "                'Target Hit Min': target_hit_ranges.apply(lambda x: x[0] if not pd.isna(x[0]) else None),\n",
    "                'Target Hit Max': target_hit_ranges.apply(lambda x: x[1] if not pd.isna(x[1]) else None),\n",
    "         \n",
    "            }\n",
    "            \n",
    "            combined_data_df = pd.DataFrame(combined_data)\n",
    "            \n",
    "            # Convert all relevant columns to numeric\n",
    "            for col in ['Stop Loss Min', 'Stop Loss Max', 'Target Hit Min', 'Target Hit Max']:\n",
    "                combined_data_df[col] = pd.to_numeric(combined_data_df[col], errors='coerce')\n",
    "            \n",
    "            # Ensure there is numeric data to plot\n",
    "            numeric_data = combined_data_df.drop(columns=['Indicator']).dropna(how='all', axis=1)\n",
    "            \n",
    "            if not numeric_data.empty:\n",
    "                combined_data_df.set_index('Indicator').plot(kind='bar', figsize=(12, 8))\n",
    "                plt.title(f'Combined Range Analysis for Best PNL Combination\\n{folder_name}')\n",
    "                plt.ylabel('Range')\n",
    "                plt.show()\n",
    "                plt.savefig(f'{output_dir}/{folder_name}_combined_range_analysis.png')\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(\"No numeric data available for combined range analysis.\")\n",
    "            \n",
    "            # Print the ranges to avoid\n",
    "            ranges_to_avoid = {}\n",
    "            for indicator in indicators:\n",
    "                stop_loss_min, stop_loss_max = combined_data_df.loc[combined_data_df['Indicator'] == indicator, ['Stop Loss Min', 'Stop Loss Max']].values[0]\n",
    "                target_hit_min, target_hit_max = combined_data_df.loc[combined_data_df['Indicator'] == indicator, ['Target Hit Min', 'Target Hit Max']].values[0]\n",
    "                \n",
    "                if pd.notna(stop_loss_min) and pd.notna(stop_loss_max):\n",
    "                    if pd.notna(target_hit_min) and pd.notna(target_hit_max):\n",
    "                        if stop_loss_min <= target_hit_min <= stop_loss_max:\n",
    "                            stop_loss_max = target_hit_min - 1e-9\n",
    "                        if stop_loss_min <= target_hit_max <= stop_loss_max:\n",
    "                            stop_loss_min = target_hit_max + 1e-9\n",
    "                    \n",
    "                    ranges_to_avoid[indicator] = (stop_loss_min, stop_loss_max)\n",
    "            \n",
    "            # Visualize the ranges to avoid\n",
    "            for indicator, avoid_range in ranges_to_avoid.items():\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                sns.histplot(stop_loss_hits[indicator], color='red', label='Stop Loss Hit', kde=True, stat=\"density\", linewidth=0)\n",
    "                sns.histplot(target_hits[indicator], color='green', label='Target Hit', kde=True, stat=\"density\", linewidth=0)\n",
    "                plt.axvspan(*avoid_range, color='red', alpha=0.3, label='Range to Avoid')\n",
    "                plt.xlabel(indicator)\n",
    "                plt.ylabel('Density')\n",
    "                plt.title(f'Distribution of {indicator} with Range to Avoid')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.savefig(f'{output_dir}/{folder_name}_{indicator}_range_to_avoid.png')\n",
    "                plt.close()\n",
    "            \n",
    "            # Save the ranges to avoid in a text file\n",
    "            with open(f'{output_dir}/{folder_name}_ranges_to_avoid.txt', 'w') as f:\n",
    "                for indicator, (min_val, max_val) in ranges_to_avoid.items():\n",
    "                    f.write(f\"{indicator}: {min_val} to {max_val}\\n\")\n",
    "            \n",
    "            return ranges_to_avoid\n",
    "        \n",
    "        # Call the function to identify ranges to avoid\n",
    "        ranges_to_avoid = identify_ranges_to_avoid()\n",
    "        \n",
    "        # Filter out trades that fall into the ranges to avoid\n",
    "        def filter_trades(trades, ranges_to_avoid):\n",
    "            for indicator, (min_val, max_val) in ranges_to_avoid.items():\n",
    "                if min_val is not None and max_val is not None:\n",
    "                    # Create a boolean mask for trades to remove\n",
    "                    mask = (trades[indicator] >= min_val) & (trades[indicator] <= max_val)\n",
    "                    trades = trades[~mask]\n",
    "            return trades\n",
    "\n",
    "        # Re-run the analysis excluding trades that fall into the ranges to avoid\n",
    "        new_trade_results_combined = []\n",
    "        new_all_combined_results = []\n",
    "        directories = [f'June 2024/{folder_name}']\n",
    "        for directory in directories:\n",
    "            folder_name = os.path.basename(directory)\n",
    "            for subdir, _, files in os.walk(directory):\n",
    "                if subdir == directory:\n",
    "                    continue  # Skip the top-level directory itself\n",
    "                for filename in files:\n",
    "                    if ', 1.csv' in filename:  # Change to ', 1.csv' for 1-minute data\n",
    "                        minute_1_path = os.path.join(subdir, filename)\n",
    "                        \n",
    "                        if os.path.exists(minute_1_path):\n",
    "                            print(f\"Re-processing {filename} in {folder_name}...\")\n",
    "                            \n",
    "                            # Load the CSV file\n",
    "                            minute_data_1 = pd.read_csv(minute_1_path)\n",
    "                            \n",
    "                            # Filter buy signals\n",
    "                            buy_signals = filter_signals(minute_data_1)\n",
    "                            \n",
    "                            # Skip if no buy signals\n",
    "                            if buy_signals.empty:\n",
    "                                print(f\"No buy signals found for {filename}. Skipping...\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Filter signals to only include those within the expiry week\n",
    "                            buy_signals = buy_signals[buy_signals['time'].apply(lambda x: is_within_expiry_week(expiry_date, x, folder_name))]\n",
    "                            \n",
    "                            # Skip if no buy signals within expiry week\n",
    "                            if buy_signals.empty:\n",
    "                                print(f\"No buy signals found within expiry week for {filename}. Skipping...\")\n",
    "                                continue\n",
    "                            \n",
    "                            # Perform the analysis\n",
    "                            analysis_results, trade_results = analyze_profit_and_stop_loss(buy_signals, minute_data_1, profit_percentages, stop_loss_percentages)\n",
    "                            \n",
    "                            # Filter out trades that fall into the ranges to avoid\n",
    "                            trade_results = filter_trades(trade_results, ranges_to_avoid)\n",
    "                            \n",
    "                            if not trade_results.empty:\n",
    "                                # Merge buy signals with trade results\n",
    "                                combined_results = pd.merge(buy_signals, trade_results, left_on='time', right_on='signal_time', how='inner')\n",
    "                                \n",
    "                                # Merge the 1-minute chart data with combined results\n",
    "                                combined_results = pd.merge(combined_results, minute_data_1, left_on='time', right_on='time', suffixes=('_buy', '_original'))\n",
    "                               \n",
    "                                new_all_combined_results.append(combined_results)\n",
    "                                new_trade_results_combined.append(trade_results)\n",
    "        \n",
    "        # Combine all results for the new filtered trades\n",
    "        if new_trade_results_combined:\n",
    "            new_combined_trade_results = pd.concat(new_trade_results_combined, ignore_index=True)\n",
    "            new_combined_all_results = pd.concat(new_all_combined_results, ignore_index=True)\n",
    "            \n",
    "            # Save the new filtered trade results to CSV files\n",
    "            new_output_dir = f'Outputs/DayTrade/SOSI/1min/{folder_name}_filtered'\n",
    "            os.makedirs(new_output_dir, exist_ok=True)\n",
    "            \n",
    "            new_combined_trade_results.to_csv(f'{new_output_dir}/{folder_name}_filtered_trade_results.csv', index=False)\n",
    "            new_combined_all_results.to_csv(f'{new_output_dir}/{folder_name}_filtered_all_combined_results.csv', index=False)\n",
    "            \n",
    "            # Re-calculate top 40 combinations for the filtered trades\n",
    "            new_combined_pnl_results = new_combined_trade_results.groupby(['Target Profit', 'Stop Loss'], as_index=False)['profit'].sum()\n",
    "            new_top_40_combinations = new_combined_pnl_results.sort_values(by='profit', ascending=False).head(40)\n",
    "            new_top_40_combinations.to_csv(f'{new_output_dir}/{folder_name}_filtered_top_40_combinations.csv', index=False)\n",
    "            \n",
    "            # Find the best combination of profit target and stop loss after filtering\n",
    "            best_combination_filtered = new_top_40_combinations.loc[new_top_40_combinations['profit'].idxmax()]\n",
    "            \n",
    "            # Filter the best trade results from the combined trade results\n",
    "            best_trade_results_filtered = new_combined_trade_results[\n",
    "                (new_combined_trade_results['Target Profit'] == best_combination_filtered['Target Profit']) & \n",
    "                (new_combined_trade_results['Stop Loss'] == best_combination_filtered['Stop Loss'])\n",
    "            ]\n",
    "            \n",
    "            # Re-summarize the best trade results after filtering\n",
    "            best_trade_summary_filtered = summarize_trade_results(best_trade_results_filtered)\n",
    "            \n",
    "            # Save the best trade summary after filtering\n",
    "            best_trade_summary_filtered_df = pd.DataFrame([best_trade_summary_filtered])\n",
    "            best_trade_summary_filtered_df.to_csv(f'{new_output_dir}/{folder_name}_filtered_best_trade_summary.csv', index=False)\n",
    "            \n",
    "            # Plot the new pie chart for best trade summary\n",
    "            labels = ['Target Hit', 'Stop Loss Hit', 'End of Day Exit']\n",
    "            sizes = [best_trade_summary_filtered['Target Hit'], best_trade_summary_filtered['Stop Loss Hit'], best_trade_summary_filtered['End of Day Exit']]\n",
    "            colors = ['lightgreen', 'lightcoral', 'lightskyblue']\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "            plt.title(f'Best Trade Summary for Best PNL Combination\\n{folder_name} (Filtered)')\n",
    "            plt.axis('equal')\n",
    "            plt.show()\n",
    "            plt.savefig(f'{new_output_dir}/{folder_name}_filtered_best_trade_summary_pie_chart.png')\n",
    "            plt.close()\n",
    "            \n",
    "            # Plot the new bar chart for total trades for best PNL\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.barh(['Total Trades'], [best_trade_summary_filtered['Total Trades']], color='skyblue')\n",
    "            plt.xlabel('Count')\n",
    "            plt.ylabel('Total Trades')\n",
    "            plt.title(f'Total Trades for Best PNL Combination\\n{folder_name} (Filtered)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig(f'{new_output_dir}/{folder_name}_filtered_total_trades_bar_chart.png')\n",
    "            plt.close()\n",
    "        \n",
    "            # Plot the new bar chart for max drawdown for best PNL\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.barh(['Max Drawdown'], [best_trade_summary_filtered['Max Drawdown']], color='red')\n",
    "            plt.xlabel('Max Drawdown')\n",
    "            plt.ylabel('Max Drawdown Value')\n",
    "            plt.title(f'Max Drawdown for Best PNL Combination\\n{folder_name} (Filtered)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig(f'{new_output_dir}/{folder_name}_filtered_max_drawdown_bar_chart.png')\n",
    "            plt.close()\n",
    "        \n",
    "            # Plot the bar chart for the top 40 combinations\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.barh(new_top_40_combinations['Target Profit'].astype(str) + \" / \" + new_top_40_combinations['Stop Loss'].astype(str),\n",
    "                     new_top_40_combinations['profit'], color='skyblue')\n",
    "            plt.xlabel('Total Profit')\n",
    "            plt.ylabel('Target Profit / Stop Loss')\n",
    "            plt.title(f'Top 40 Profit Target and Stop Loss Combinations\\n{folder_name} (Filtered)')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig(f'{new_output_dir}/{folder_name}_filtered_top_40_combinations.png')\n",
    "            plt.close()\n",
    "        \n",
    "        else:\n",
    "            print(f\"No trades remaining after filtering for {folder_name}.\")\n",
    "  \n",
    "print(\"Analysis complete.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
